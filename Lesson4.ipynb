{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd93239d-fd55-4b85-b23d-94f3e3bbab1f",
   "metadata": {},
   "source": [
    "# Lesson 4 - Compare with P.2108 Clutter Model\n",
    "\n",
    "In this lesson you'll compare the performance of your clutter propagation model with the P.2108 clutter model.\n",
    "\n",
    "### About P.2108\n",
    " * __The documentation__ for the P.2108 clutter model can be found at [Recommendation ITU-R P.2108-1](https://www.itu.int/dms_pubrec/itu-r/rec/p/R-REC-P.2108-1-202109-I!!PDF-E.pdf).\n",
    " * __The code repository__ for NTIA's reference implementation of P.2108 can be found at [NTIA/p2108](https://github.com/NTIA/p2108) GitHub repository.\n",
    "\n",
    "The P.2108 model estimates signal loss through clutter for frequencies between 300 MHz and 100 GHz. P.2108 is composed of three methods for predicting clutter loss depending on the situation:\n",
    "1. Height Gain Terminal Correction Model, for 0.3 to 3 GHz\n",
    "2. Terrestrial Statistical Model, for 2 to 67 GHz\n",
    "3. Aeronautical Statistical Model, for 10 to 100 GHz\n",
    "\n",
    "In this lesson we will use the __Terrestrial Statistical Model__ because the measurement data was made with two ground-based terminals and the frequency is 3.5 GHz. A full description of the Terrestrial Statistical Model can be found in section 3.2 of Recommendation ITU-R P.2108-1 linked above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab445e-2447-4e56-8f4b-55e2be21605e",
   "metadata": {},
   "source": [
    "### Import the P.2108 code library\n",
    "The [NTIA code repository for P.2108](https://github.com/NTIA/p2108) contains the U.S. Reference Implementation for all three P.2108 clutter loss prediction methods listed above. To use this software we have provided an installable Python package in the following directory path: **`course-materials/packages/p2108-1.0.0-py3-none-any.whl`**. \n",
    "\n",
    "Execute the following cell to install the P.2108 package in your JupyterLab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b802a4c-cdc6-491c-bfc3-64448d9c13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install packages/p2108-1.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c09bde0-dfbb-44e8-9349-ebe876d1850c",
   "metadata": {},
   "source": [
    "### Import the necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce2602-bf5d-4fe5-88d5-1d1c96fb3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ITS.ITU.PSeries import P2108\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92d116-cbda-46f2-89b3-113b5415cc23",
   "metadata": {},
   "source": [
    "### How to use P.2108\n",
    "\n",
    "We will use the __Terrestrial Statistical Model__ from P.2108. This model is a statistical clutter loss model for terrestrial propagation paths. It is valid for urban and suburban clutter environments. The predicted clutter loss is a correction factor for a single terminal within the clutter. The correction can be applied to both terminals if both are within the clutter (which we will not do since the transmitter is located above the clutter). A description of the model and the inputs and outputs can be found on the [NTIA/p2108 repository README](https://github.com/NTIA/p2108?tab=readme-ov-file#terrestrial-statistical-model).\n",
    "\n",
    "#### P2108.TerrestrialStatisticalModel( `f__ghz` , `d__km` , `p` )\n",
    "\n",
    "#### Parameters: \n",
    "__`f__ghz` : float__\\\n",
    "Frequency (in GHz) of the signal. Range: 2 <= `f__ghz` <= 67.\n",
    "\n",
    "__`d__km` : float__\\\n",
    "Path distance (in kilometers) between the transmitter and receiver. Range: 0.25 <= `d__km`.\n",
    "\n",
    "__`p` : float__\\\n",
    "The clutter loss not exceeded for `p` percent of locations. Range: 0 < `p` < 100.\n",
    "\n",
    "## Examples of calling P.2108\n",
    "\n",
    "### Predict the clutter loss for: 3.5 GHz, 0.95 km, and median (50th percentile) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b3417e-22b0-497b-9a3c-d916810b602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_loss__dB = P2108.TerrestrialStatisticalModel(3.5, 0.95, 50)\n",
    "print(\"Predicted clutter loss = {:.1f} dB\".format(clutter_loss__dB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f266b-9a7e-46a8-8a82-973ece84314b",
   "metadata": {},
   "source": [
    "### Predict the clutter loss for: 3.5 GHz, 0.95 km, and 10th percentile loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091e7f2-546c-4080-873c-f2271c07c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_loss__dB = P2108.TerrestrialStatisticalModel(3.5, 0.95, 10)\n",
    "print(\"Predicted clutter loss = {:.1f} dB\".format(clutter_loss__dB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f92108-c344-4e0a-b04c-31a67d409b05",
   "metadata": {},
   "source": [
    "### Predict the clutter loss for: 3.5 GHz, 0.95 km, and 90th percentile loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdc382-6675-4cac-84a2-dab5d2d47bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_loss__dB = P2108.TerrestrialStatisticalModel(3.5, 0.95, 90)\n",
    "print(\"Predicted clutter loss = {:.1f} dB\".format(clutter_loss__dB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a5382-7347-4c33-88ed-bbd5ed559971",
   "metadata": {},
   "source": [
    "The _p_ input lets us explore the statistical bounds of the model. For the propagation of a 3.5 GHz signal, across 0.95 km, with one terminal within the clutter, P.2108 predicts that the median loss (_p_ = 50) will be 30.0 dB. P.2108 also predicts that 80% (from 10th to 90th percentile) of clutter losses observed will be between 24.4 and 35.5 dB.\n",
    "\n",
    "### Make P.2108 predictions using Martin Acres dataset path distances\n",
    "\n",
    "1. Start by loading the Martin Acres measurement data. This is the same data that was introduced in lesson 3 except the measurements with paths shorter than 0.25 km are removed (they're not supported by P.2108).\n",
    "2. Perform P.2108 predictions assuming median (50th percentile) losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97693825-483c-4b93-af73-793c86eafc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the Martin Acres dataset\n",
    "greater_0p25_df = pd.read_csv(\"data/MartinAcres_Lesson4.csv\")\n",
    "## do P.2108 predictions (ask for 50th percentile losses), create a new column with those predictions\n",
    "greater_0p25_df[\"p2108__dB\"] = greater_0p25_df.apply(lambda row: P2108.TerrestrialStatisticalModel(row.f__mhz/1000, row.d__km, 50), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea094c-d2a4-4e57-8de5-12880c482d00",
   "metadata": {},
   "source": [
    "### Plot the P.2108 predictions with the Martin Acres measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52bb71-5628-43c5-a512-2aeddbf00e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (11,6)\n",
    "\n",
    "## plot the measurement data\n",
    "plt.scatter(greater_0p25_df[\"d__km\"], greater_0p25_df[\"L_excess__db\"], label='Measurement Data', s=12)\n",
    "## plot the P.2108 predictions\n",
    "plt.plot(np.sort(greater_0p25_df[\"d__km\"]), np.sort(greater_0p25_df[\"p2108__dB\"]), label='P.2108 Prediction', c='tab:orange', linewidth=3.0)\n",
    "\n",
    "plt.xlabel('Path Distance (km)')\n",
    "plt.ylabel('Clutter Loss (dB)')\n",
    "plt.title('Path Distance vs Clutter Loss\\nMartin Acres')\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8853738-ebd0-4091-8690-0704806d2414",
   "metadata": {},
   "source": [
    "### How did P.2108 do?\n",
    "For this dataset, P.2108 appears to accurately capture clutter loss at shorter distances (less than 1 km). At 1.5 km there is a cluster of measurement data not accurately predicted by P.2108. It over predicts the clutter loss for this cluster. If you remember back to lesson 3, this cluster of measurements is from the High TX location. For the High TX, the signal suffers less because the signal passes over most buildings and trees without interference.  \n",
    "\n",
    "### Compare your model (Lesson 3) to P.2108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ba5c7-f469-4018-a5d6-ea1df4f9a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the measurement data\n",
    "plt.scatter(greater_0p25_df[\"d__km\"], greater_0p25_df[\"L_excess__db\"], label='Measurement Data', s=12)\n",
    "## plot the P.2108 predictions\n",
    "plt.plot(np.sort(greater_0p25_df[\"d__km\"]), np.sort(greater_0p25_df[\"p2108__dB\"]), label='P.2108 Prediction', c='tab:orange', linewidth=3.0)\n",
    "## plot your model\n",
    "plt.scatter(greater_0p25_df[\"d__km\"], greater_0p25_df[\"pred_loss\"], label='Model Prediction (Lesson 3)', s=10, c='tab:green')\n",
    "\n",
    "plt.xlabel('Path Distance (km)')\n",
    "plt.ylabel('Clutter Loss (dB)')\n",
    "plt.title('Comparing the Lesson 3 Model to P.2108\\nMartin Acres')\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7c418-092f-4414-9b52-fed36dd1dac1",
   "metadata": {},
   "source": [
    "Admittedly, this comparison is a little funky. The model you made in lesson 3 doesn't follow a nice curve when examined through Path Distance (the X axis). Recall that your model uses _3D Clutter Distance_, the distance that the signal travels before it exits out of the clutter. So comparing to P.2108 is a little tricky when the X axis restricted to Path Distance. \n",
    "\n",
    "Regardless of the wonky comparison, you can still see that __your model outperforms P.2108 when predicting clutter loss for transmitters at differing elevations__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63920225-4085-403a-a75a-378013d2d49a",
   "metadata": {},
   "source": [
    "### Finally, look at the Cumulative Distribution Functions (CDF) of predictions for both models\n",
    "\n",
    "Another way to understand these models is to look at their distribution of clutter loss predictions based on the Path Distance (or 3D Clutter Distance). To do this, plot the CDF of a) the measurement data, b) P.2108, and c) your clutter model. \n",
    "\n",
    "Start by defining the clutter model you made in lesson 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587fc38-c520-47b2-8927-d6f3fb70b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define your model from Lesson 3\n",
    "slope = 13.71\n",
    "y_int = -9.8\n",
    "model_std = 3.8 ## standard deviation of the model (lesson 3)\n",
    "## define a clutter model method, takes the 3D Clutter Distance (in meters) as input\n",
    "def clutter_model(clutter_distance__m):\n",
    "    return slope * np.log10(clutter_distance__m) + y_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f521a7-4f6d-47c7-8bb4-7c085e4f5faa",
   "metadata": {},
   "source": [
    "Next, find the distribution of clutter loss predictions from your model. Ensure that the predicted sample has the same __3D Clutter Distance__ distribution as the measurement data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6a20e-d9dc-4364-b20c-0aa4021c2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the distribution of 3D Clutter Distances in the Martin Acres dataset\n",
    "clutter_distances_array = np.sort(greater_0p25_df[\"clutter_d__meter\"])\n",
    "\n",
    "## Predict the clutter loss using your lesson 3 clutter model\n",
    "model_cdf_distri = []\n",
    "for d in clutter_distances_array:\n",
    "    model_cdf_distri.append(np.random.normal(clutter_model(d), model_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b8f48-56c6-499e-baff-1b48a4a1a503",
   "metadata": {},
   "source": [
    "Next, find the distribution of clutter loss predictions from P.2108. Ensure that the predicted sample has the same __Path Distance__ distribution as the measurement data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c4a93-f8a4-496e-93f8-5d9c375fe477",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the distribution of Path Distances in the Martin Acres dataset\n",
    "distances_array = np.sort(greater_0p25_df[\"d__km\"])\n",
    "\n",
    "## Predict the clutter loss using P.2108\n",
    "p2108_cdf_distri = []\n",
    "for d in distances_array:\n",
    "    p2108_cdf_distri.append(P2108.TerrestrialStatisticalModel(greater_0p25_df[\"f__mhz\"][0]/1000, d, np.random.randint(1,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3893d6f-98bb-4300-9127-5271e34a7ac4",
   "metadata": {},
   "source": [
    "### Plot the CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeddd85-add6-45a8-9c96-38e499df2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (11,6)\n",
    "\n",
    "meas_N = len(greater_0p25_df)\n",
    "meas_x = np.sort(greater_0p25_df[\"L_excess__db\"])\n",
    "meas_y = np.arange(meas_N) / float(meas_N)\n",
    "## plot the CDF\n",
    "plt.plot(meas_x, meas_y, label='Measurement Data', linewidth=3.0)\n",
    "\n",
    "p2108_x = np.sort(np.array(p2108_cdf_distri))\n",
    "p2108_y = np.arange(meas_N) / float(meas_N)\n",
    "## plot the CDF\n",
    "plt.plot(p2108_x, p2108_y, label='P.2108', linewidth=3.0)\n",
    "\n",
    "model_x = np.sort(np.array(model_cdf_distri))\n",
    "model_y = np.arange(meas_N) / float(meas_N)\n",
    "## plot the CDF\n",
    "plt.plot(model_x, model_y, label='Model (Lesson 3)', linewidth=3.0)\n",
    "\n",
    "plt.xlabel('Clutter Loss (dB)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Clutter Loss CDF')\n",
    "\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7fe28-818c-4ec6-9538-4c43f4d875a6",
   "metadata": {},
   "source": [
    "The distribution of clutter losses predicted by your model (from lesson 3) is close to actual distribution of clutter losses observed in the Martin Acres measurement data. P.2108 appears to generally overpredict the clutter loss by 3-5 dB. This is another good indicator that your model outperforms P.2108 in situations where the transmitter is above the clutter.\n",
    "\n",
    "### One last thing\n",
    "\n",
    "Before ending this lesson it's important to discuss why P.2108 doesn't perform well with this dataset. P.2108's Terrestrial Statistical Model assumes that all propagation paths are completely horizontal through clutter (a 0-degree RX elevation angle). It also assumes that propagation paths that are _near_ horizontal will suffer the same loss as a _completely_ horizontal path. This turns out not to be true. If we look at the Martin Acres measurements, the Low TX data has an average RX elevation angle of 1 degree and the High TX data has an average RX elevation angle of 4 degrees. Both are near zero and could be assumed to suffer the same clutter loss as a completely horizontal path. Yet we see a big difference, especially from the High TX dataset. In short, a 4-degree RX elevation angle is enough to disrupt P.2108's predictive power.\n",
    "\n",
    "Well done, you've compared your statistical clutter model to the P.2108 clutter model. In the next lesson you'll see how good (or bad) your clutter model performs with other datasets.\n",
    "\n",
    "End of Lesson 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
